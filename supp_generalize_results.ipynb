{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "\n",
    "from prepare_datasets_HCSC import load_data_HCSC\n",
    "from prepare_datasets_ADNI import load_data_ADNI, process_descriptive_variables\n",
    "from clusters_description import label_A, label_T, label_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid', font='Arial', font_scale=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define datasets/cohorts\n",
    "### Discovery dataset: HCSC cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects: 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laura/anaconda3/envs/biomarkers/lib/python3.8/site-packages/pandas/core/indexes/base.py:6982: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "file_dis = 'data/HCSC/BaseLCR_24julio22conATNparaLaura.sav'\n",
    "des_dis, csf_dis, cog_dis = load_data_HCSC(file_dis)\n",
    "des_dis['DxclinBreve'].replace({'EA GDS3':'LMCI',\n",
    "                                'EApreMCI':'EMCI',\n",
    "                                'Control/QSM':'SMC',\n",
    "                                'Otros':'MCI-NN'}, inplace=True)\n",
    "des_dis = des_dis.drop([510673, 1175866, 1106441, 622301, 2378737])\n",
    "csf_dis = csf_dis.drop([510673, 1175866, 1106441, 622301, 2378737])\n",
    "x_dis = csf_dis[['RatioR', 'TAUtotal', 'pTAU']].dropna()\n",
    "print('Number of subjects:', x_dis.shape[0])\n",
    "\n",
    "# Scaling data\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(x_dis)\n",
    "x_dis_scaled  = scaler.transform(x_dis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation dataset: ADNI cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects: 174\n"
     ]
    }
   ],
   "source": [
    "# Validation cohort\n",
    "val_file = 'data/ADNI/UPENNBIOMK10_07_29_19_19Jun2023.csv'\n",
    "csf_val = pd.read_csv(val_file, index_col='RID')\n",
    "csf_val = csf_val.loc[csf_val['VISCODE2'] == 'bl']\n",
    "csf_val = csf_val[['ABETA42', 'ABETA40', 'TAU', 'PTAU']].dropna()\n",
    "csf_val['AB4240'] = csf_val['ABETA42'] / csf_val['ABETA40']\n",
    "\n",
    "des_val = pd.read_csv('data/ADNI/descriptive_variables.csv', low_memory=False, index_col='RID')\n",
    "des_val = des_val.drop(index=des_val.loc[des_val['DX_bl'] == 'AD'].index) # Delete dementia patients\n",
    "\n",
    "x_val = pd.concat([csf_val[['AB4240', 'TAU', 'PTAU']], des_val['DX_bl']], axis=1, join='inner')\n",
    "x_val.drop(columns=['DX_bl'], inplace=True)\n",
    "print('Number of subjects:', x_val.shape[0])\n",
    "\n",
    "# Scaling data\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(x_val)\n",
    "x_val_scaled  = scaler.transform(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.5297\n",
      "3 0.5527\n",
      "4 0.5279\n",
      "5 0.496\n",
      "6 0.4511\n",
      "7 0.3772\n",
      "8 0.3795\n",
      "9 0.377\n",
      "10 0.3735\n"
     ]
    }
   ],
   "source": [
    "for n in range(2, 11):\n",
    "\n",
    "    km = KMeans(n_clusters=n, max_iter=1000, random_state=42, n_init=100)\n",
    "    y_km = km.fit_predict(x_dis_scaled)\n",
    "\n",
    "    si = round(silhouette_score(x_dis_scaled, y_km, metric='euclidean'), 4)\n",
    "    print(n, si) \n",
    "\n",
    "   # optimal number of clusters: n = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering model\n",
    "Train clustering model on dicovery cohort and obtain clusters in discovery and validation cohorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovery (train): 0.5527\n",
      "Validation (test)  0.3847\n"
     ]
    }
   ],
   "source": [
    "km = KMeans(n_clusters=3, max_iter=1000, random_state=42, n_init=100)\n",
    "y_train = km.fit_predict(x_dis_scaled)\n",
    "y_test  = km.predict(x_val_scaled)\n",
    "\n",
    "si_train = round(silhouette_score(x_dis_scaled, y_train, metric='euclidean'), 4)\n",
    "si_test  = round(silhouette_score(x_val_scaled, y_test, metric='euclidean'), 4)\n",
    "\n",
    "print('Discovery (train):', si_train)\n",
    "print('Validation (test) ', si_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of clusters\n",
    "Train a simple classification model (Logistic Regression) using discovery cohort (HCSC dataset) and evaluate or test it using validation cohort (ADNI cohort)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_weighted</th>\n",
       "      <th>test_recall_weighted</th>\n",
       "      <th>test_f1_weighted</th>\n",
       "      <th>test_matthews_corrcoef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006631</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002879</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.949580</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.941478</td>\n",
       "      <td>0.911616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002967</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.929167</td>\n",
       "      <td>0.899388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003032</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.929167</td>\n",
       "      <td>0.899388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002959</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
       "0  0.006631    0.003604       1.000000                 1.000000   \n",
       "1  0.003866    0.002170       1.000000                 1.000000   \n",
       "2  0.002879    0.001812       0.941176                 0.949580   \n",
       "3  0.002618    0.002016       1.000000                 1.000000   \n",
       "4  0.002967    0.001843       1.000000                 1.000000   \n",
       "5  0.002760    0.001824       0.937500                 0.945312   \n",
       "6  0.003032    0.001800       0.937500                 0.945312   \n",
       "7  0.002880    0.001863       1.000000                 1.000000   \n",
       "8  0.002853    0.001853       1.000000                 1.000000   \n",
       "9  0.002959    0.001771       1.000000                 1.000000   \n",
       "\n",
       "   test_recall_weighted  test_f1_weighted  test_matthews_corrcoef  \n",
       "0              1.000000          1.000000                1.000000  \n",
       "1              1.000000          1.000000                1.000000  \n",
       "2              0.941176          0.941478                0.911616  \n",
       "3              1.000000          1.000000                1.000000  \n",
       "4              1.000000          1.000000                1.000000  \n",
       "5              0.937500          0.929167                0.899388  \n",
       "6              0.937500          0.929167                0.899388  \n",
       "7              1.000000          1.000000                1.000000  \n",
       "8              1.000000          1.000000                1.000000  \n",
       "9              1.000000          1.000000                1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='lbfgs', random_state=42, max_iter=1000)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_results = cross_validate(model, x_dis_scaled, y_train, cv=kfold,\n",
    "                            scoring=['accuracy','precision_weighted',\n",
    "                                     'recall_weighted','f1_weighted',\n",
    "                                     'matthews_corrcoef'])\n",
    "clf = model.fit(x_dis_scaled, y_train)\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        86\n",
      "           1       0.87      0.90      0.88        67\n",
      "           2       0.95      0.86      0.90        21\n",
      "\n",
      "    accuracy                           0.91       174\n",
      "   macro avg       0.92      0.89      0.90       174\n",
      "weighted avg       0.91      0.91      0.91       174\n",
      "\n",
      "[[80  6  0]\n",
      " [ 6 60  1]\n",
      " [ 0  3 18]]\n",
      "\n",
      "Accuracy:  0.908\n",
      "Precision: 0.9089\n",
      "Recall   : 0.908\n",
      "F1-Score:  0.9081\n",
      "MCC:       0.8443\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(x_val_scaled)\n",
    "\n",
    "print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "print(confusion_matrix(y_pred=y_pred, y_true=y_test))\n",
    "print()\n",
    "\n",
    "acc = metrics.accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "pre = metrics.precision_score(y_pred=y_pred, y_true=y_test, average='weighted')\n",
    "rec = metrics.recall_score(y_pred=y_pred, y_true=y_test, average='weighted')\n",
    "f1  = metrics.f1_score(y_pred=y_pred, y_true=y_test, average='weighted')\n",
    "mcc = metrics.matthews_corrcoef(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "print('Accuracy: ', round(acc, 4))\n",
    "print('Precision:', round(pre, 4))\n",
    "print('Recall   :', round(rec, 4))\n",
    "print('F1-Score: ', round(f1, 4))\n",
    "print('MCC:      ', round(mcc, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
